2025-01-23 10:18:11 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.200:9093]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-prod-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = prod-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-23 10:18:11 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initializing the Kafka consumer
2025-01-23 10:18:11 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 10:18:11 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 10:18:11 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737645491832
2025-01-23 10:18:11 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Kafka consumer initialized
2025-01-23 10:18:11 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Subscribed to topic(s): my-topic-prod
2025-01-23 10:18:11 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Sending FindCoordinator request to broker 192.168.2.200:9093 (id: -1 rack: null)
2025-01-23 10:18:12 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:245) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:96) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:111) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:78) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:33) [classes/:?]
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 10:18:14 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 10:18:14 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-prod-group-1, correlationId=0) due to node -1 being disconnected
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] FindCoordinator request failed due to {}
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 10:18:14 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:22:17 INFO  [main] org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.2.200:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2025-01-23 16:22:17 INFO  [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2025-01-23 16:22:17 INFO  [main] org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-01-23 16:22:17 INFO  [main] org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-23 16:22:17 INFO  [main] org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
2025-01-23 16:22:17 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2025-01-23 16:22:17 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2025-01-23 16:22:29 INFO  [main] org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.2.200:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2025-01-23 16:22:30 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:22:30 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:22:30 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737667350245
2025-01-23 16:22:30 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:22:30 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:45:51 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.200:9093]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-prod-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = prod-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-23 16:45:51 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initializing the Kafka consumer
2025-01-23 16:45:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:45:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:45:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737668751994
2025-01-23 16:45:51 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Kafka consumer initialized
2025-01-23 16:45:52 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Subscribed to topic(s): my-topic-prod
2025-01-23 16:45:52 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Sending FindCoordinator request to broker 192.168.2.200:9093 (id: -1 rack: null)
2025-01-23 16:45:52 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:245) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:45:54 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:45:54 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-prod-group-1, correlationId=0) due to node -1 being disconnected
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] FindCoordinator request failed due to {}
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 16:45:54 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:45:56 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:164) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:257) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:45:56 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:45:56 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:45:56 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:45:56 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:45:56 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 16:45:56 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:164) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:257) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:45:58 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:45:58 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 16:45:58 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:46:00 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:164) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:257) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:46:00 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:46:00 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:46:00 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 16:46:01 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:164) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:257) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:46:03 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:46:03 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:03 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:04 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:04 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:04 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:04 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initialize connection to node 192.168.2.200:9093 (id: -1 rack: null) for sending metadata request
2025-01-23 16:46:04 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9093 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection with /192.168.2.200 disconnected
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_302]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_302]
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:224) ~[kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:561) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:227) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:164) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:257) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:480) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1232) [kafka-clients-2.8.0.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1165) [kafka-clients-2.8.0.jar:?]
	at com.kafka.KafkaConsumerService.consumeMessages(KafkaConsumerService.java:44) [classes/:?]
	at com.kafka.KafkaManager.runConsumer(KafkaManager.java:101) [classes/:?]
	at com.kafka.KafkaManager.run(KafkaManager.java:71) [classes/:?]
	at picocli.CommandLine.executeUserObject(CommandLine.java:2026) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.access$1500(CommandLine.java:148) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417) [picocli-4.7.4.jar:4.7.4]
	at picocli.CommandLine.execute(CommandLine.java:2170) [picocli-4.7.4.jar:4.7.4]
	at com.kafka.KafkaManager.main(KafkaManager.java:31) [classes/:?]
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Node -1 disconnected.
2025-01-23 16:46:06 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Connection to node -1 (/192.168.2.200:9093) could not be established. Broker may not be available.
2025-01-23 16:46:06 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Bootstrap broker 192.168.2.200:9093 (id: -1 rack: null) disconnected
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:06 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Give up sending metadata request since no node is available
2025-01-23 16:46:50 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.200:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-prod-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = prod-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-23 16:46:50 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initializing the Kafka consumer
2025-01-23 16:46:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:46:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:46:51 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737668811257
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Kafka consumer initialized
2025-01-23 16:46:51 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Subscribed to topic(s): my-topic-prod
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Sending FindCoordinator request to broker 192.168.2.200:9092 (id: -1 rack: null)
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Initiating API versions fetch from node -1.
2025-01-23 16:46:51 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-prod-group-1, groupId=prod-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-prod-group-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:47:14 INFO  [main] org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.2.200:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:47:14 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:47:14 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:47:14 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737668834595
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:47:14 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:47:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:47:44 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:47:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:48:14 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Exception occurred during message send:
org.apache.kafka.common.errors.TimeoutException: Topic my-topic-dev not present in metadata after 60000 ms.
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:48:44 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:48:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=2) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:48:46 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.200:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initializing the Kafka consumer
2025-01-23 16:48:46 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:48:46 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:48:46 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737668926606
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Kafka consumer initialized
2025-01-23 16:48:46 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): my-topic-dev
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending FindCoordinator request to broker 192.168.2.200:9092 (id: -1 rack: null)
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:48:46 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:49:14 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Exception occurred during message send:
org.apache.kafka.common.errors.TimeoutException: Topic my-topic-dev not present in metadata after 60000 ms.
2025-01-23 16:49:16 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:49:16 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:49:16 DEBUG [main] org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-dev-group-1, correlationId=0) due to node -1 being disconnected
2025-01-23 16:49:16 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] FindCoordinator request failed due to {}
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:49:16 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:49:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=2) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:49:44 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:49:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=3) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:49:47 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:49:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=3) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:50:14 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Exception occurred during message send:
org.apache.kafka.common.errors.TimeoutException: Topic my-topic-dev not present in metadata after 60000 ms.
2025-01-23 16:50:14 INFO  [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-01-23 16:50:14 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:50:17 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:50:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=4) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:50:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:50:44 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:50:44 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Shutdown of Kafka producer I/O thread has completed.
2025-01-23 16:50:44 INFO  [main] org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-01-23 16:50:44 INFO  [main] org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-23 16:50:44 INFO  [main] org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
2025-01-23 16:50:44 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2025-01-23 16:50:44 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:50:47 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:50:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=5) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:51:17 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:51:17 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=6) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:51:47 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:51:47 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=7) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:52:24 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.200:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-23 16:52:24 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initializing the Kafka consumer
2025-01-23 16:52:25 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:52:25 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:52:25 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737669145212
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Kafka consumer initialized
2025-01-23 16:52:25 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): my-topic-dev
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending FindCoordinator request to broker 192.168.2.200:9092 (id: -1 rack: null)
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:52:25 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node -1 due to request timeout.
2025-01-23 16:52:55 WARN  [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-dev-group-1, correlationId=0) due to node -1 being disconnected
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] FindCoordinator request failed due to {}
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.DisconnectException: null
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Completed connection to node -1. Fetching API versions.
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Initiating API versions fetch from node -1.
2025-01-23 16:52:55 DEBUG [main] org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-dev-group-1, correlationId=2) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:54:09 INFO  [main] org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.2.200:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:54:09 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:54:09 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:54:09 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737669249415
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:54:09 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:54:09 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:54:39 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:54:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:55:09 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Exception occurred during message send:
org.apache.kafka.common.errors.TimeoutException: Topic my-topic-dev not present in metadata after 60000 ms.
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:55:39 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:55:39 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=2) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:56:05 INFO  [main] org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.2.200:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-01-23 16:56:06 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2025-01-23 16:56:06 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:56:06 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.8.0
2025-01-23 16:56:06 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: ebb1d6e21cc92130
2025-01-23 16:56:06 INFO  [main] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1737669366389
2025-01-23 16:56:06 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:56:06 DEBUG [main] org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
2025-01-23 16:56:49 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to socket connection setup timeout. The timeout value is 8775 ms.
2025-01-23 16:56:49 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:56:50 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Disconnecting from node -1 due to request timeout.
2025-01-23 16:57:20 WARN  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Bootstrap broker 192.168.2.200:9092 (id: -1 rack: null) disconnected
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 192.168.2.200:9092 (id: -1 rack: null) for sending metadata request
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 192.168.2.200:9092 (id: -1 rack: null) using address /192.168.2.200
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2025-01-23 16:57:20 DEBUG [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='2.8.0')
