# Apache Kafka KRaft 3.0 Architecture

## Overview of KRaft Mode

KRaft (Kafka Raft) removes the dependency on ZooKeeper by implementing a Raft-based consensus protocol. The metadata is now managed by a quorum of controller nodes instead of ZooKeeper.

## Core Components

### 1. **Controller Quorum**
- Dedicated controller nodes that manage cluster metadata
- Use Raft consensus protocol for leader election and replication
- Store metadata in an internal `__cluster_metadata` topic
- Requires odd number of controllers (3 or 5 recommended for production)

### 2. **Broker Nodes**
- Can be combined mode (controller + broker) or separate
- Fetch metadata from active controller
- Handle client requests for producing/consuming

### 3. **Metadata Management**
- All metadata stored in Raft log on controllers
- Brokers replicate metadata via MetadataFetch requests
- No external coordination system needed

---

## SASL/SSL Configuration

### Authentication & Encryption Layers

**SASL (Simple Authentication and Security Layer)**: Authentication
**SSL/TLS**: Encryption and optionally authentication via certificates

### Ports Used

| Component | Port | Protocol | Purpose |
|-----------|------|----------|---------|
| Controller | 9093 | SASL_SSL | Inter-controller communication |
| Broker (clients) | 9092 | PLAINTEXT | Unencrypted client connections |
| Broker (clients) | 9094 | SASL_SSL | Encrypted + authenticated clients |
| Broker (inter-broker) | 9091 | SASL_SSL | Broker-to-broker communication |

---

## Certificate Requirements

### 1. **Certificate Authority (CA)**
```bash
# Generate CA private key
openssl genrsa -out ca-key.pem 2048

# Generate CA certificate
openssl req -new -x509 -key ca-key.pem -out ca-cert.pem -days 365 \
  -subj "/C=US/ST=State/L=City/O=Organization/CN=Kafka-CA"
```

### 2. **Server Certificates** (for each broker/controller)

```bash
# Generate broker private key
openssl genrsa -out broker1-key.pem 2048

# Create certificate signing request
openssl req -new -key broker1-key.pem -out broker1.csr \
  -subj "/C=US/ST=State/L=City/O=Organization/CN=broker1.example.com"

# Sign with CA
openssl x509 -req -in broker1.csr -CA ca-cert.pem -CAkey ca-key.pem \
  -CAcreateserial -out broker1-cert.pem -days 365

# Create keystore (Java format)
openssl pkcs12 -export -in broker1-cert.pem -inkey broker1-key.pem \
  -out broker1.p12 -name broker1 -password pass:broker1pass

keytool -importkeystore -srckeystore broker1.p12 -srcstoretype PKCS12 \
  -destkeystore broker1.keystore.jks -deststoretype JKS \
  -srcstorepass broker1pass -deststorepass broker1pass
```

### 3. **Truststore** (contains CA certificate)

```bash
keytool -import -file ca-cert.pem -alias CARoot \
  -keystore kafka.truststore.jks -storepass truststorepass -noprompt
```

### Certificate Files Needed per Node:
- **keystore.jks**: Contains node's private key and certificate
- **truststore.jks**: Contains CA certificate to trust other nodes
- **ca-cert.pem**: CA certificate

---

## Configuration Examples

### Controller Node Configuration (server.properties)

```properties
# Process role
process.roles=controller
node.id=1
controller.quorum.voters=1@controller1:9093,2@controller2:9093,3@controller3:9093

# Listeners
listeners=CONTROLLER://controller1:9093
controller.listener.names=CONTROLLER
inter.broker.listener.name=CONTROLLER

# Metadata log directory
metadata.log.dir=/var/kafka/kraft-metadata

# SSL Configuration for Controller
listener.security.protocol.map=CONTROLLER:SASL_SSL
ssl.keystore.location=/etc/kafka/ssl/controller1.keystore.jks
ssl.keystore.password=keystorepass
ssl.key.password=keypass
ssl.truststore.location=/etc/kafka/ssl/kafka.truststore.jks
ssl.truststore.password=truststorepass
ssl.client.auth=required

# SASL Configuration for Controller
sasl.mechanism.controller.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
listener.name.controller.sasl.enabled.mechanisms=PLAIN
listener.name.controller.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="controller" \
  password="controller-secret" \
  user_controller="controller-secret" \
  user_broker1="broker1-secret" \
  user_broker2="broker2-secret";

# Enable SSL for inter-controller communication
ssl.endpoint.identification.algorithm=https
```

### Broker Node Configuration (server.properties)

```properties
# Process role
process.roles=broker
node.id=101
controller.quorum.voters=1@controller1:9093,2@controller2:9093,3@controller3:9093

# Listeners
listeners=INTERNAL://broker1:9091,CLIENT://broker1:9094
advertised.listeners=INTERNAL://broker1:9091,CLIENT://broker1.example.com:9094
inter.broker.listener.name=INTERNAL

# Security protocol mapping
listener.security.protocol.map=INTERNAL:SASL_SSL,CLIENT:SASL_SSL,CONTROLLER:SASL_SSL

# Log directories
log.dirs=/var/kafka/kafka-logs
metadata.log.dir=/var/kafka/kraft-metadata

# SSL Configuration
ssl.keystore.location=/etc/kafka/ssl/broker1.keystore.jks
ssl.keystore.password=keystorepass
ssl.key.password=keypass
ssl.truststore.location=/etc/kafka/ssl/kafka.truststore.jks
ssl.truststore.password=truststorepass
ssl.client.auth=required
ssl.endpoint.identification.algorithm=https

# SASL Configuration for connecting to controllers
sasl.mechanism.controller.protocol=PLAIN
listener.name.controller.sasl.enabled.mechanisms=PLAIN
listener.name.controller.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="broker1" \
  password="broker1-secret";

# SASL Configuration for inter-broker communication
listener.name.internal.sasl.enabled.mechanisms=PLAIN
listener.name.internal.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="broker1" \
  password="broker1-secret" \
  user_broker1="broker1-secret" \
  user_broker2="broker2-secret";

# SASL Configuration for client connections
listener.name.client.sasl.enabled.mechanisms=SCRAM-SHA-512
sasl.enabled.mechanisms=SCRAM-SHA-512

# Authorizer configuration
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin;User:broker1;User:broker2
```

---

## ACL (Access Control Lists) Configuration

### Enable Authorization

KRaft uses the **StandardAuthorizer** (replaces SimpleAclAuthorizer):

```properties
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:admin
```

### Creating SCRAM Users

```bash
# Create admin user
kafka-configs.sh --bootstrap-server broker1:9094 \
  --command-config client.properties \
  --alter --add-config 'SCRAM-SHA-512=[password=admin-secret]' \
  --entity-type users --entity-name admin

# Create producer user
kafka-configs.sh --bootstrap-server broker1:9094 \
  --command-config client.properties \
  --alter --add-config 'SCRAM-SHA-512=[password=producer-secret]' \
  --entity-type users --entity-name producer-app

# Create consumer user
kafka-configs.sh --bootstrap-server broker1:9094 \
  --command-config client.properties \
  --alter --add-config 'SCRAM-SHA-512=[password=consumer-secret]' \
  --entity-type users --entity-name consumer-app
```

### ACL Examples

**1. Allow producer to write to specific topic:**
```bash
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:producer-app \
  --operation Write --topic orders

# Also need DESCRIBE and CREATE for topic
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:producer-app \
  --operation Describe --operation Create --topic orders
```

**2. Allow consumer to read from topic and consumer group:**
```bash
# Read from topic
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:consumer-app \
  --operation Read --topic orders

# Describe topic
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:consumer-app \
  --operation Describe --topic orders

# Access consumer group
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:consumer-app \
  --operation Read --group order-consumer-group
```

**3. Allow wildcard access to topic pattern:**
```bash
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --add --allow-principal User:analytics-app \
  --operation Read --operation Describe \
  --topic 'analytics-*' --resource-pattern-type prefixed
```

**4. List all ACLs:**
```bash
kafka-acls.sh --bootstrap-server broker1:9094 \
  --command-config admin.properties \
  --list
```

---

## Connection Flow Examples

### 1. **Controller-to-Controller Connection**

**Port**: 9093 (SASL_SSL)

```
Controller-1                              Controller-2
    |                                          |
    |-- TCP Handshake on port 9093 ---------->|
    |                                          |
    |<-- SSL/TLS Handshake ------------------>|
    |    (Certificate exchange & validation)  |
    |                                          |
    |-- SASL/PLAIN Authentication ----------->|
    |   (username: controller, password: xxx) |
    |                                          |
    |<-- Authentication Success --------------|
    |                                          |
    |<-- Raft Protocol Messages ------------->|
    |    (Vote requests, AppendEntries, etc)  |
```

**Certificates Used**:
- Controller's keystore.jks (for server identity)
- Truststore.jks (to validate peer controllers)

---

### 2. **Broker-to-Controller Connection**

**Port**: 9093 (SASL_SSL)

```
Broker-1                                  Controller-1
    |                                          |
    |-- TCP Connect to 9093 ----------------->|
    |                                          |
    |<-- SSL/TLS Handshake ------------------>|
    |    (Broker validates controller cert)   |
    |    (Controller validates broker cert)   |
    |                                          |
    |-- SASL/PLAIN Authentication ----------->|
    |   (username: broker1, password: xxx)    |
    |                                          |
    |<-- Authentication Success --------------|
    |                                          |
    |-- MetadataFetch Request ---------------->|
    |                                          |
    |<-- Metadata Response (topics, ACLs) ----|
```

**Certificates Used**:
- Broker's keystore.jks
- Truststore.jks with CA cert

---

### 3. **Inter-Broker Connection**

**Port**: 9091 (SASL_SSL)

```
Broker-1 (Leader)                         Broker-2 (Follower)
    |                                          |
    |-- TCP Connect to 9091 ----------------->|
    |                                          |
    |<-- SSL/TLS Handshake ------------------>|
    |                                          |
    |-- SASL Authentication ----------------->|
    |                                          |
    |-- Fetch Request (for replication) ----->|
    |                                          |
    |<-- Fetch Response (messages) ------------|
```

**Certificates Used**:
- Each broker's keystore.jks
- Shared truststore.jks

---

### 4. **Client-to-Broker Connection**

**Port**: 9094 (SASL_SSL with SCRAM-SHA-512)

```
Producer Client                           Broker-1
    |                                          |
    |-- TCP Connect to 9094 ----------------->|
    |                                          |
    |<-- SSL/TLS Handshake ------------------>|
    |    (Client validates broker cert)       |
    |                                          |
    |-- SASL/SCRAM-SHA-512 Challenge -------->|
    |                                          |
    |<-- Server Nonce + Salt -----------------|
    |                                          |
    |-- Client Proof (hashed password) ------>|
    |                                          |
    |<-- Server Verification -----------------|
    |                                          |
    |-- ProduceRequest (topic: orders) ------->|
    |                                          |
    |   [Broker checks ACL for User:producer] |
    |   [ACL: ALLOW Write on topic=orders]    |
    |                                          |
    |<-- ProduceResponse (success) ------------|
```

**Client Configuration** (producer.properties):
```properties
bootstrap.servers=broker1.example.com:9094
security.protocol=SASL_SSL

# SSL settings
ssl.truststore.location=/etc/kafka/client/kafka.truststore.jks
ssl.truststore.password=truststorepass
ssl.endpoint.identification.algorithm=https

# SASL settings
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="producer-app" \
  password="producer-secret";
```

**Certificates Needed by Client**:
- **truststore.jks** only (to validate broker's certificate)
- No client certificate needed (authentication via SCRAM)

---

## Complete Certificate Chain

```
Certificate Authority (CA)
    ca-key.pem (private key)
    ca-cert.pem (public certificate)
    
    ├── Controller-1
    │   ├── controller1.keystore.jks (private key + signed cert)
    │   └── kafka.truststore.jks (CA cert)
    │
    ├── Controller-2
    │   ├── controller2.keystore.jks
    │   └── kafka.truststore.jks
    │
    ├── Broker-1
    │   ├── broker1.keystore.jks
    │   └── kafka.truststore.jks
    │
    ├── Broker-2
    │   ├── broker2.keystore.jks
    │   └── kafka.truststore.jks
    │
    └── Clients (Producers/Consumers)
        └── kafka.truststore.jks (only)
```

---

## Initialization Steps

### 1. Format Storage
```bash
# Generate cluster ID
CLUSTER_ID=$(kafka-storage.sh random-uuid)

# Format controller nodes
kafka-storage.sh format -t $CLUSTER_ID -c /etc/kafka/controller.properties

# Format broker nodes
kafka-storage.sh format -t $CLUSTER_ID -c /etc/kafka/broker.properties
```

### 2. Start Controllers First
```bash
kafka-server-start.sh /etc/kafka/controller1.properties
```

### 3. Start Brokers
```bash
kafka-server-start.sh /etc/kafka/broker1.properties
```

### 4. Verify Cluster
```bash
kafka-metadata.sh --snapshot /var/kafka/kraft-metadata/__cluster_metadata-0/*.checkpoint --print
```

---

## Key Differences from ZooKeeper Mode

| Aspect | ZooKeeper Mode | KRaft Mode |
|--------|----------------|------------|
| Metadata storage | External ZooKeeper ensemble | Internal Raft log |
| Dependency | Requires ZooKeeper (3+ nodes) | Self-contained |
| Ports | ZooKeeper: 2181, 2888, 3888 | Controller: 9093 only |
| ACL storage | ZooKeeper znodes | `__cluster_metadata` topic |
| Configuration | ZooKeeper connection string | `controller.quorum.voters` |
| Startup | Start ZK then Kafka | Format then start controllers |

---

This configuration provides enterprise-grade security with:
- ✅ Encrypted communication (SSL/TLS)
- ✅ Mutual authentication (certificates + SASL)
- ✅ Fine-grained authorization (ACLs)
- ✅ Password hashing (SCRAM-SHA-512)
- ✅ No external dependencies (KRaft mode)


https://claude.ai/public/artifacts/694409f6-a4b4-47b0-8d4b-d96666e054af
