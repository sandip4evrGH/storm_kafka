```bash
# 1. Download and Extract Kafka 3.9.0
wget https://downloads.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz
tar -xzf kafka_2.13-3.9.0.tgz
cd kafka_2.13-3.9.0

# 2. Create Kafka Data Directory
mkdir -p /var/lib/kafka-data

# 3. Generate Node ID
NODE_ID=$(uuidgen)

# 4. Generate SSL Certificates (Self-Signed for Testing)
# Replace with proper certificates for production
KEYSTORE_PASS="kafkastore"
TRUSTSTORE_PASS="kafkastore"

keytool -genkey -alias kafka -keyalg RSA -keystore kafka.keystore.jks -validity 365 -storepass $KEYSTORE_PASS -dname "CN=localhost"
keytool -export -alias kafka -keystore kafka.keystore.jks -file kafka.cer -storepass $KEYSTORE_PASS
keytool -import -alias kafka -file kafka.cer -keystore kafka.truststore.jks -storepass $TRUSTSTORE_PASS

# 5. Server Configuration (config/kraft/server.properties)
cat <<EOF > config/kraft/server.properties
node.id=$NODE_ID
process.roles=broker,controller
controller.quorum.voters=$NODE_ID@localhost:9093
listeners=PLAINTEXT://localhost:9092,CONTROLLER://localhost:9093,SSL://localhost:9094
advertised.listeners=SSL://localhost:9094
log.dirs=/var/lib/kafka-data
security.inter.broker.protocol=SSL
listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,SSL:SSL
ssl.keystore.location=kafka.keystore.jks
ssl.keystore.password=$KEYSTORE_PASS
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
ssl.client.auth=none # or requested or required
zookeeper.connect=unused
EOF

# 6. Start Kafka Server
bin/kafka-server-start.sh config/kraft/server.properties

# 7. Client Configuration (producer.properties, consumer.properties, admin-client.properties)

cat <<EOF > config/producer.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

cat <<EOF > config/consumer.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

cat <<EOF > config/admin-client.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

# 8. Create Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --create --topic my-ssl-topic --partitions 1 --replication-factor 1 --command-config config/admin-client.properties

# 9. Produce Messages (SSL)
bin/kafka-console-producer.sh --bootstrap-server localhost:9094 --topic my-ssl-topic --producer.config config/producer.properties

# 10. Consume Messages (SSL)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 --topic my-ssl-topic --from-beginning --consumer.config config/consumer.properties

# 11. Describe Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --describe --topic my-ssl-topic --command-config config/admin-client.properties
```

**Explanation and Key Points:**

1.  **Download and Extract:** Downloads and extracts Kafka 3.9.0.
2.  **Data Directory:** Creates the directory for Kafka data.
3.  **Node ID:** Generates a unique node ID.
4.  **Generate SSL Certificates:**
    * `keytool` is used to create self-signed certificates for testing.
    * **For production, replace these with certificates from a trusted CA.**
    * `kafka.keystore.jks`: Contains the Kafka broker's private key and certificate.
    * `kafka.truststore.jks`: Contains the trusted certificates (in this case, the broker's own certificate).
    * The passwords for both keystore and truststore are set to "kafkastore" for testing.
5.  **Server Configuration:**
    * `listeners=SSL://localhost:9094`: Enables SSL on port 9094.
    * `advertised.listeners=SSL://localhost:9094`: Advertises the SSL listener to clients.
    * `security.inter.broker.protocol=SSL`: Enables SSL for inter-broker communication.
    * `listener.security.protocol.map=SSL:SSL`: Maps the SSL listener to the SSL protocol.
    * `ssl.keystore.location`, `ssl.keystore.password`, `ssl.truststore.location`, `ssl.truststore.password`: Specifies the locations and passwords for the keystore and truststore.
    * `ssl.client.auth=none`: Disables client authentication. You can set it to `requested` or `required` for mutual TLS.
6.  **Start Kafka Server:** Starts the Kafka broker.
7.  **Client Configuration:**
    * `producer.properties`, `consumer.properties`, and `admin-client.properties`: Configure the clients to use SSL.
    * `ssl.truststore.location` and `ssl.truststore.password`: Specifies the truststore for the clients.
8.  **Create Topic:** Creates the `my-ssl-topic` topic.
9.  **Produce Messages:** Produces messages to the topic over SSL.
10. **Consume Messages:** Consumes messages from the topic over SSL.
11. **Describe Topic:** Describes the topic.

**Important Notes:**

* **Production Certificates:** Replace the self-signed certificates with certificates from a trusted CA for production use.
* **Client Authentication:** Consider enabling client authentication (`ssl.client.auth=required`) for enhanced security.
* **Port Numbers:** Adjust the port numbers as needed.
* **Keystore/Truststore Security:** Store the keystore and truststore files securely.
* **Firewall:** Ensure that the necessary ports are open in your firewall.
* **Hostnames/IP Addresses:** Replace `localhost` with the appropriate hostnames or IP addresses.
* **KRAFT:** This configuration is for Kafka KRAFT mode.
* **No Zookeeper:** This configuration does not use Zookeeper.







# 1. Download and Extract Kafka 3.9.0
wget https://downloads.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz
tar -xzf kafka_2.13-3.9.0.tgz
cd kafka_2.13-3.9.0

# 2. Create Kafka Data Directory
mkdir -p /var/lib/kafka-data

# 3. Generate Node ID
NODE_ID=$(uuidgen)

# 4. Generate SSL Certificates (Self-Signed for Testing)
# Replace with proper certificates for production
KEYSTORE_PASS="kafkastore"
TRUSTSTORE_PASS="kafkastore"

keytool -genkey -alias kafka -keyalg RSA -keystore kafka.keystore.jks -validity 365 -storepass $KEYSTORE_PASS -dname "CN=localhost"
keytool -export -alias kafka -keystore kafka.keystore.jks -file kafka.cer -storepass $KEYSTORE_PASS
keytool -import -alias kafka -file kafka.cer -keystore kafka.truststore.jks -storepass $TRUSTSTORE_PASS

# 5. Server Configuration (config/kraft/server.properties) - SSL Only
cat <<EOF > config/kraft/server.properties
node.id=$NODE_ID
process.roles=broker,controller
controller.quorum.voters=$NODE_ID@localhost:9093
listeners=CONTROLLER://localhost:9093,SSL://localhost:9094
advertised.listeners=SSL://localhost:9094
log.dirs=/var/lib/kafka-data
security.inter.broker.protocol=SSL
listener.security.protocol.map=CONTROLLER:PLAINTEXT,SSL:SSL
ssl.keystore.location=kafka.keystore.jks
ssl.keystore.password=$KEYSTORE_PASS
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
ssl.client.auth=none # or requested or required
zookeeper.connect=unused
EOF

# 6. Start Kafka Server
bin/kafka-server-start.sh config/kraft/server.properties

# 7. Client Configuration (producer.properties, consumer.properties, admin-client.properties)

cat <<EOF > config/producer.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

cat <<EOF > config/consumer.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

cat <<EOF > config/admin-client.properties
security.protocol=SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
EOF

# 8. Create Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --create --topic my-ssl-topic --partitions 1 --replication-factor 1 --command-config config/admin-client.properties

# 9. Produce Messages (SSL)
bin/kafka-console-producer.sh --bootstrap-server localhost:9094 --topic my-ssl-topic --producer.config config/producer.properties

# 10. Consume Messages (SSL)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 --topic my-ssl-topic --from-beginning --consumer.config config/consumer.properties

# 11. Describe Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --describe --topic my-ssl-topic --command-config config/admin-client.properties



















```bash
# 1. Download and Extract Kafka 3.9.0
wget https://downloads.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz
tar -xzf kafka_2.13-3.9.0.tgz
cd kafka_2.13-3.9.0

# 2. Create Kafka Data Directory
mkdir -p /var/lib/kafka-data

# 3. Generate Node ID
NODE_ID=$(uuidgen)

# 4. Generate SSL Certificates (Self-Signed for Testing)
# Replace with proper certificates for production
KEYSTORE_PASS="kafkastore"
TRUSTSTORE_PASS="kafkastore"

keytool -genkey -alias kafka -keyalg RSA -keystore kafka.keystore.jks -validity 365 -storepass $KEYSTORE_PASS -dname "CN=localhost"
keytool -export -alias kafka -keystore kafka.keystore.jks -file kafka.cer -storepass $KEYSTORE_PASS
keytool -import -alias kafka -file kafka.cer -keystore kafka.truststore.jks -storepass $TRUSTSTORE_PASS

# 5. Generate User Passwords
PASSWORD=$(openssl rand -base64 32)
ADMIN_PASSWORD=$(openssl rand -base64 32)

# 6. Server Configuration (config/kraft/server.properties) - SSL and SCRAM, no PLAINTEXT
cat <<EOF > config/kraft/server.properties
node.id=$NODE_ID
process.roles=broker,controller
controller.quorum.voters=$NODE_ID@localhost:9093
listeners=SSL://localhost:9093,SASL_SSL://localhost:9094
advertised.listeners=SASL_SSL://localhost:9094
log.dirs=/var/lib/kafka-data
security.inter.broker.protocol=SASL_SSL
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-512
sasl.enabled.mechanisms=SCRAM-SHA-512
listener.security.protocol.map=SSL:SSL,SASL_SSL:SASL_SSL
ssl.keystore.location=kafka.keystore.jks
ssl.keystore.password=$KEYSTORE_PASS
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
ssl.client.auth=required # or requested or none. required is recommended for production
zookeeper.connect=unused
EOF

# 7. Start Kafka Server
bin/kafka-server-start.sh config/kraft/server.properties

# 8. Create Kafka Users (AFTER Kafka start)
bin/kafka-configs.sh --bootstrap-server localhost:9093 --alter --add-config 'SCRAM-SHA-512=[iterations=8192,password=$PASSWORD]' --entity-type users --entity-name myuser
bin/kafka-configs.sh --bootstrap-server localhost:9093 --alter --add-config 'SCRAM-SHA-512=[iterations=8192,password=$ADMIN_PASSWORD]' --entity-type users --entity-name admin

# 9. Client Configuration (producer.properties, consumer.properties, admin-client.properties) - SSL and SCRAM

cat <<EOF > config/producer.properties
security.protocol=SASL_SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="myuser" password="$PASSWORD";
EOF

cat <<EOF > config/consumer.properties
security.protocol=SASL_SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="myuser" password="$PASSWORD";
EOF

cat <<EOF > config/admin-client.properties
security.protocol=SASL_SSL
ssl.truststore.location=kafka.truststore.jks
ssl.truststore.password=$TRUSTSTORE_PASS
sasl.mechanism=SCRAM-SHA-512
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="$ADMIN_PASSWORD";
EOF

# 10. Create Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --create --topic my-ssl-scram-topic --partitions 1 --replication-factor 1 --command-config config/admin-client.properties

# 11. Produce Messages (SSL and SCRAM)
bin/kafka-console-producer.sh --bootstrap-server localhost:9094 --topic my-ssl-scram-topic --producer.config config/producer.properties

# 12. Consume Messages (SSL and SCRAM)
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 --topic my-ssl-scram-topic --from-beginning --consumer.config config/consumer.properties

# 13. Describe Topic (Admin)
bin/kafka-topics.sh --bootstrap-server localhost:9094 --describe --topic my-ssl-scram-topic --command-config config/admin-client.properties
```

**Key Changes:**

* **No PLAINTEXT:**
    * `listeners=SSL://localhost:9093,SASL_SSL://localhost:9094`: The PLAINTEXT listener has been removed, and the controller listener has been changed to use SSL.
    * `listener.security.protocol.map=SSL:SSL,SASL_SSL:SASL_SSL`: The plaintext mapping has been removed.
* **Controller Listener SSL:**
    * The controller listener now uses SSL on port 9093. This is for all inter broker and controller communication.
* **SSL Client Authentication:**
    * `ssl.client.auth=required`: Client authentication is now required.
* **User creation port:**
    * The user creation commands now use port 9093, since that is the SSL enabled controller port.

**Important Notes:**

* Production Certificates are still required for production.
* Client authentication is required in this setup.
* All inter broker and client communication is now SSL enabled.
* The user creation commands must be run after the kafka broker is started.
















You got it! Let's consolidate all that goodness into a text file structure you can easily work with for your Kafka 3.9 KRAFT setup with SASL_SSL and ACLs.
Here's how the kafka_secure_setup.txt file would look:
# Kafka 3.9 KRAFT Setup with SASL_SSL and ACLs

## 1. Broker Configuration (server.properties)

```properties
broker.id=0
process.roles=broker,controller
node.id=0

listeners=SASL_SSL://localhost:9092,CONTROLLER://localhost:9093
advertised.listeners=your_public_ip:9092 # Replace with your broker's public IP or resolvable hostname
inter.broker.listener.name=SASL_SSL
controller.listener.names=CONTROLLER

log.dirs=/tmp/kafka-logs

offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2

default.replication.factor=3
min.insync.replicas=2

controller.quorum.voters=0@localhost:9093 # List of controller nodes (node.id@host:port)

security.inter.broker.protocol=SASL_SSL

sasl.mechanism.inter.broker.protocol=PLAIN # Or SCRAM-SHA-256/SCRAM-SHA-512 for stronger security
sasl.enabled.mechanisms=PLAIN # Or SCRAM-SHA-256/SCRAM-SHA-512

ssl.protocol=TLSv1.3 # Or TLSv1.2
ssl.enabled.protocols=TLSv1.2,TLSv1.3
ssl.endpoint.identification.algorithm=https # Recommended for production
ssl.truststore.location=/path/to/your/kafka.truststore.jks # Replace with the actual path
ssl.truststore.password=your_truststore_password # Replace with your truststore password
ssl.keystore.location=/path/to/your/kafka.keystore.jks # Replace with the actual path
ssl.keystore.password=your_keystore_password # Replace with your keystore password
ssl.key.password=your_key_password # Replace with your key password (if different from keystore password)

authorizer.class.name=kafka.security.authorizer.AclAuthorizer
allow.everyone.if.no.acl.found=false # Important for enabling ACLs

Explanation of Broker Properties:
 * broker.id: A unique numerical ID for each broker in the Kafka cluster.
 * process.roles: Defines the roles this process will fulfill. In a KRAFT setup, a node can be both a broker and a controller.
 * node.id: The unique ID of this node, must match broker.id when a node serves as both broker and controller.
 * listeners: The network addresses the Kafka broker will listen on.
   * SASL_SSL://localhost:9092: Listens for client connections using SASL for authentication and SSL/TLS for encryption.
   * CONTROLLER://localhost:9093: Listens for internal controller communication.
 * advertised.listeners: The addresses clients will use to connect to the broker. This is crucial if your clients are on a different network than your brokers. Replace your_public_ip with the actual accessible address.
 * inter.broker.listener.name: The listener name used for communication between brokers.
 * controller.listener.names: The listener name used for communication with the active controller.
 * log.dirs: The directory where Kafka will store its log data.
 * offsets.topic.replication.factor: The replication factor for the internal __consumer_offsets topic. Higher values provide better fault tolerance.
 * transaction.state.log.replication.factor: The replication factor for the internal transaction state log.
 * transaction.state.log.min.isr: The minimum number of in-sync replicas required for the transaction state log to acknowledge a write.
 * default.replication.factor: The default replication factor for newly created topics.
 * min.insync.replicas: The minimum number of in-sync replicas required for a broker to acknowledge a write request. This prevents data loss.
 * controller.quorum.voters: A list of all controller nodes in the Kafka cluster, in the format node.id@host:port. If you have multiple controllers, list them all here (e.g., 0@host1:9093,1@host2:9093).
 * security.inter.broker.protocol: The protocol used for communication between brokers.
 * sasl.mechanism.inter.broker.protocol: The SASL mechanism used for inter-broker authentication. PLAIN is basic, consider SCRAM-SHA-256 or SCRAM-SHA-512 for better security in production.
 * sasl.enabled.mechanisms: The SASL mechanisms enabled for client authentication.
 * ssl.protocol: The highest SSL/TLS protocol version the broker will support.
 * ssl.enabled.protocols: The specific SSL/TLS protocol versions enabled. It's good practice to disable older, less secure protocols.
 * ssl.endpoint.identification.algorithm: Enables hostname verification, which is recommended to prevent man-in-the-middle attacks.
 * ssl.truststore.location: The path to the Java truststore file containing the certificates of trusted entities (e.g., Certificate Authorities or other brokers). Replace with the actual path.
 * ssl.truststore.password: The password for the truststore. Replace with your truststore password.
 * ssl.keystore.location: The path to the Java keystore file containing the broker's own certificate and private key. Replace with the actual path.
 * ssl.keystore.password: The password for the keystore. Replace with your keystore password.
 * ssl.key.password: The password for the private key within the keystore (if different from the keystore password). Replace with your key password (if different).
 * authorizer.class.name: Specifies the authorizer implementation to use. kafka.security.authorizer.AclAuthorizer enables ACL-based authorization.
 * allow.everyone.if.no.acl.found: When set to false, any operation without a corresponding ACL will be denied. This is crucial for enforcing security.
2. Client Configuration (client.properties)
security.protocol=SASL_SSL
sasl.mechanism=PLAIN # Or SCRAM-SHA-256/SCRAM-SHA-512 to match broker
ssl.truststore.location=/path/to/your/client.truststore.jks # Replace with the actual path
ssl.truststore.password=your_client_truststore_password # Replace with your truststore password

# SASL username and password for authentication
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="testuser" password="testpassword";

# Bootstrap servers (replace with your broker address(es))
bootstrap.servers=your_public_ip:9092

Explanation of Client Properties:
 * security.protocol: Specifies the security protocol to use when communicating with the broker. Must match the broker's listener configuration (SASL_SSL).
 * sasl.mechanism: The SASL mechanism to use for authentication. Must match one of the mechanisms enabled on the broker.
 * ssl.truststore.location: The path to the client's truststore file, containing the certificates of the Kafka brokers. Replace with the actual path.
 * ssl.truststore.password: The password for the client's truststore. Replace with your truststore password.
 * sasl.jaas.config: Configuration for the Java Authentication and Authorization Service (JAAS). This specifies the login module to use (PlainLoginModule for the PLAIN mechanism) and provides the username and password for authentication. Replace "testuser" and "testpassword" with the actual credentials for the user you are testing.
 * bootstrap.servers: A comma-separated list of host and port pairs that are the addresses of the Kafka brokers. The client will contact these initial servers to discover the full set of brokers in the cluster. If you have multiple brokers, list them here (e.g., your_public_ip1:9092,your_public_ip2:9092).
3. Adding Testing Users and Setting ACLs
You can manage users and ACLs using the Kafka command-line tools.
For PLAIN SASL Mechanism:
You need to configure users directly in the broker's JAAS configuration file. Create a file (e.g., kafka_server_jaas.conf) with the following content:
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="user1" password="password1"
  username="user2" password="password2";
};

Then, when starting the Kafka broker, include the following JVM option:
-Djava.security.auth.login.config=/path/to/your/kafka_server_jaas.conf

For SCRAM-SHA-256 or SCRAM-SHA-512 (recommended for production):
Use the kafka-configs.sh command:
./bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type users --entity-name user1 --add-config 'SCRAM-SHA-256=[password=user1secret]'
./bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type users --entity-name user2 --add-config 'SCRAM-SHA-512=[password=user2secure]'

Setting ACLs:
Use the kafka-acls.sh command to grant permissions to the users.
 * Allow user1 to produce to topic test-topic:
   ./bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --producer --topic test-topic

 * Allow user2 to consume from topic test-topic in group my-group:
   ./bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user2 --consumer --topic test-topic --group my-group

 * Allow user1 to create topics:
   ./bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --operation Create --cluster

 * Deny user2 from deleting topics:
   ./bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --deny-principal User:user2 --operation Delete --cluster

Listing Existing ACLs:
./bin/kafka-acls.sh --bootstrap-server localhost:9092 --list

Removing ACLs:
Use the --remove option with similar parameters used for adding.
4. Testing Connection and ACLs
Here are the commands to test the connection and verify the ACLs are working as expected. Make sure you have created client configuration files (client.properties or variations) with the appropriate sasl.jaas.config for each user you are testing.
Test Producer (as user1):
./bin/kafka-console-producer.sh --bootstrap-server your_public_ip:9092 --topic test-topic --producer.config /path/to/client_user1.properties

Test Producer (as user2 - should fail):
./bin/kafka-console-producer.sh --bootstrap-server your_public_ip:9092 --topic test-topic --producer.config /path/to/client_user2.properties

Test Consumer (as user2, group my-group):
./bin/kafka-console-consumer.sh --bootstrap-server your_public_ip:9092 --topic test-topic --group my-group --consumer.config /path/to/client_user2.properties --from-beginning

Test Consumer (as user1, group my-group - should fail):
./bin/kafka-console-consumer.sh --bootstrap-server your_public_ip:9092 --topic test-topic --group my-group --consumer.config /path/to/client_user1.properties --from-beginning

Remember to replace all the placeholder paths and passwords with your actual values!
You can save this entire content into a text file named kafka_secure_setup.txt. This should give you a clear and organized reference for setting up your secure Kafka environment with KRAFT. Let me know if you need any adjustments or further details!
