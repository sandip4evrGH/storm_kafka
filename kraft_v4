# Terraform Project Structure for Kafka KRaft Cluster

Below is a complete, structured Terraform project for deploying a 12-node Kafka KRaft 3.9 cluster on AWS. I've rewritten and organized the code for clarity, modularity, and best practices. The project is self-contained under a directory like `tf-kafka-user-data`.

## Directory Structure
```
tf-kafka-user-data/
├── main.tf                  # Main Terraform configuration (providers, locals, resources)
├── variables.tf             # Variable definitions
├── outputs.tf               # Output definitions
└── templates/               # Template files for configurations
    ├── server.properties.tftpl  # Kafka server properties template
    ├── user_data.sh.tftpl       # User data script template for instance initialization
    └── kafka.service.tftpl      # Systemd service file template for Kafka
```

## Rewritten Code Files

### main.tf
```hcl
provider "aws" {
  region = "us-west-2"
}

locals {
  azs = ["a", "b", "c"]
  controller_node_ids = [1, 5, 9]
  nodes = {
    for i in range(1, 13) : tostring(i) => {
      node_id       = i
      hostname      = i == 11 ? "dnaarc-cat-Kafkal-nll" : format("dnaarc-cat-Kafkal-n%d", i)
      fqdn          = format("%s.us-west-2.aws.cloud.bofa", i == 11 ? "dnaarc-cat-Kafkal-nll" : format("dnaarc-cat-Kafkal-n%d", i))
      az_index      = floor((i - 1) / 4)
      subnet_id     = var.subnet_ids[floor((i - 1) / 4)]
      rack          = format("us-west-2%s", local.azs[floor((i - 1) / 4)])
      is_controller = contains(local.controller_node_ids, i)
    }
  }
  controller_quorum_voters = join(",", [
    for id in local.controller_node_ids : format("%d@%s:9093", id, local.nodes[tostring(id)].fqdn)
  ])
}

data "aws_secretsmanager_secret" "keystore" {
  name = var.keystore_secret_name
}

data "aws_secretsmanager_secret_version" "keystore" {
  secret_id = data.aws_secretsmanager_secret.keystore.id
}

data "aws_secretsmanager_secret" "key" {
  name = var.key_secret_name
}

data "aws_secretsmanager_secret_version" "key" {
  secret_id = data.aws_secretsmanager_secret.key.id
}

data "aws_secretsmanager_secret" "truststore" {
  name = var.truststore_secret_name
}

data "aws_secretsmanager_secret_version" "truststore" {
  secret_id = data.aws_secretsmanager_secret.truststore.id
}

data "cloudinit_config" "kafka" {
  for_each = local.nodes

  gzip          = false
  base64_encode = false

  part {
    filename     = "server.properties"
    content_type = "text/plain"
    content      = templatefile("${path.module}/templates/server.properties.tftpl", {
      node_id                   = each.value.node_id
      is_controller             = each.value.is_controller
      fqdn                      = each.value.fqdn
      controller_quorum_voters  = local.controller_quorum_voters
      broker_rack               = each.value.rack
      keystore_password         = data.aws_secretsmanager_secret_version.keystore.secret_string
      key_password              = data.aws_secretsmanager_secret_version.key.secret_string
      truststore_password       = data.aws_secretsmanager_secret_version.truststore.secret_string
    })
  }

  part {
    filename     = "/etc/systemd/system/kafka.service"
    content_type = "text/plain"
    content      = templatefile("${path.module}/templates/kafka.service.tftpl", {})
  }

  part {
    content_type = "text/x-shellscript"
    content      = templatefile("${path.module}/templates/user_data.sh.tftpl", {
      fqdn                 = each.value.fqdn
      java_s3_path         = var.java_s3_path
      python_s3_path       = var.python_s3_path
      kafka_s3_path        = var.kafka_s3_path
      certs_s3_path        = var.certs_s3_path
      config_s3_bucket     = var.config_s3_bucket
    })
  }
}

resource "aws_launch_template" "kafka" {
  for_each = local.nodes

  name                   = "kafka-node-${each.value.node_id}"
  image_id               = var.ami_id
  instance_type          = var.instance_type
  vpc_security_group_ids = [var.security_group_id]
  iam_instance_profile {
    name = var.iam_instance_profile_name
  }
  user_data = base64encode(data.cloudinit_config.kafka[each.key].rendered)

  block_device_mappings {
    device_name = "/dev/sdf"

    ebs {
      volume_size           = 100
      volume_type           = "gp3"
      delete_on_termination = true
      throughput            = 125
      iops                  = 3000
    }
  }

  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_autoscaling_group" "kafka" {
  for_each = local.nodes

  name                  = "kafka-node-${each.value.node_id}-asg"
  min_size              = 1
  max_size              = 1
  desired_capacity      = 1
  vpc_zone_identifier   = [each.value.subnet_id]
  protect_from_scale_in = false

  launch_template {
    id      = aws_launch_template.kafka[each.key].id
    version = aws_launch_template.kafka[each.key].latest_version
  }

  tag {
    key                 = "Name"
    value               = "kafka-node-${each.value.node_id}"
    propagate_at_launch = true
  }

  lifecycle {
    create_before_destroy = true
  }
}
```

### variables.tf
```hcl
variable "subnet_ids" {
  description = "List of subnet IDs, one per AZ (a, b, c)"
  type        = list(string)
}

variable "security_group_id" {
  description = "Security group ID for Kafka instances"
  type        = string
}

variable "ami_id" {
  description = "AMI ID for the instances"
  type        = string
}

variable "instance_type" {
  description = "Instance type for Kafka nodes"
  type        = string
  default     = "m5.large"
}

variable "iam_instance_profile_name" {
  description = "IAM instance profile name for S3 access"
  type        = string
}

variable "java_s3_path" {
  description = "S3 path to Java tar.gz"
  type        = string
}

variable "python_s3_path" {
  description = "S3 path to Python tar.gz"
  type        = string
}

variable "kafka_s3_path" {
  description = "S3 path to Kafka 3.9 tar.gz"
  type        = string
}

variable "certs_s3_path" {
  description = "S3 path to certs tar.gz (containing keystore.jks, truststore.jks)"
  type        = string
}

variable "config_s3_bucket" {
  description = "S3 bucket for shared config like cluster_id"
  type        = string
}

variable "keystore_secret_name" {
  description = "Name of the AWS Secrets Manager secret for keystore password"
  type        = string
}

variable "key_secret_name" {
  description = "Name of the AWS Secrets Manager secret for key password"
  type        = string
}

variable "truststore_secret_name" {
  description = "Name of the AWS Secrets Manager secret for truststore password"
  type        = string
}
```

### outputs.tf
```hcl
output "asg_names" {
  description = "Names of the Auto Scaling Groups"
  value       = { for k, v in aws_autoscaling_group.kafka : k => v.name }
}
```

### templates/server.properties.tftpl
```
process.roles=${is_controller ? "broker,controller" : "broker"}
node.id=${node_id}
controller.quorum.voters=${controller_quorum_voters}

listeners=SASL_SSL://0.0.0.0:9092${is_controller ? ",CONTROLLER://0.0.0.0:9093" : ""}
advertised.listeners=SASL_SSL://${fqdn}:9092
listener.security.protocol.map=SASL_SSL:SASL_SSL,CONTROLLER:SASL_SSL

inter.broker.listener.name=SASL_SSL
controller.listener.names=CONTROLLER
control.plane.listener.name=CONTROLLER

sasl.enabled.mechanisms=SCRAM-SHA-512
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-512
sasl.mechanism.controller.protocol=SCRAM-SHA-512

authorizer.class.name=org.apache.kafka.server.authorizer.AclAuthorizer
allow.everyone.if.no.acl.found=true
super.users=User:admin  # Adjust as needed; initial setup required for secure bootstrap

ssl.keystore.location=/opt/kafka/config/certs/keystore.jks
ssl.keystore.password=${keystore_password}
ssl.key.password=${key_password}
ssl.truststore.location=/opt/kafka/config/certs/truststore.jks
ssl.truststore.password=${truststore_password}
ssl.client.auth=required
ssl.enabled.protocols=TLSv1.2,TLSv1.3
ssl.keystore.type=JKS
ssl.truststore.type=JKS

broker.rack=${broker_rack}
log.dirs=/opt/kafka/logs

num.network.threads=6
num.io.threads=12
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000

auto.create.topics.enable=false
delete.topic.enable=true
group.initial.rebalance.delay.ms=3000
offsets.retention.minutes=1440
offsets.topic.num.partitions=50
offsets.topic.segment.bytes=104857600
zookeeper.session.timeout.ms=18000  # Though KRaft, some configs might still apply or be placeholders
background.threads=10
num.replica.fetchers=2
replica.fetch.max.bytes=1048576
replica.fetch.response.max.bytes=10485760
```

### templates/user_data.sh.tftpl
```
#!/bin/bash
set -ex

# Set hostname
hostnamectl set-hostname ${fqdn}
echo "preserve_hostname: true" | tee -a /etc/cloud/cloud.cfg

# Mount and format EBS volume if necessary
DEVICE=/dev/xvdf  # AWS maps /dev/sdf to /dev/xvdf
MOUNT_DIR=/opt/kafka/logs

if ! blkid $DEVICE; then
  mkfs -t ext4 $DEVICE
fi

mkdir -p $MOUNT_DIR
mount $DEVICE $MOUNT_DIR || true  # In case already mounted
echo "$DEVICE $MOUNT_DIR ext4 defaults,nofail 0 2" >> /etc/fstab

# Download and install Java
aws s3 cp ${java_s3_path} /opt/java.tar.gz
mkdir -p /opt/java
tar -xzf /opt/java.tar.gz -C /opt/java --strip-components=1
rm /opt/java.tar.gz
export JAVA_HOME=/opt/java
echo "export JAVA_HOME=/opt/java" >> /etc/profile.d/java.sh
echo "export PATH=$PATH:$JAVA_HOME/bin" >> /etc/profile.d/java.sh

# Download and install Python
aws s3 cp ${python_s3_path} /opt/python.tar.gz
mkdir -p /opt/python
tar -xzf /opt/python.tar.gz -C /opt/python --strip-components=1
rm /opt/python.tar.gz
echo "export PATH=/opt/python/bin:$PATH" >> /etc/profile.d/python.sh

# Download and install Kafka
aws s3 cp ${kafka_s3_path} /opt/kafka.tar.gz
tar -xzf /opt/kafka.tar.gz -C /opt
mv /opt/apache-kafka-3.9.0 /opt/kafka  # Adjust version if needed
rm /opt/kafka.tar.gz

# Download certs
aws s3 cp ${certs_s3_path} /opt/certs.tar.gz
mkdir -p /opt/kafka/config/certs
tar -xzf /opt/certs.tar.gz -C /opt/kafka/config/certs
rm /opt/certs.tar.gz

# Handle cluster ID
cd /opt/kafka
CLUSTER_ID_PATH="s3://${config_s3_bucket}/kafka_cluster_id"
if ! aws s3 cp $CLUSTER_ID_PATH ./cluster_id 2>/dev/null; then
  bin/kafka-storage.sh random-uuid > cluster_id
  aws s3 cp cluster_id $CLUSTER_ID_PATH
fi

# Format storage (assuming /opt/kafka/logs is log.dirs)
bin/kafka-storage.sh format --ignore-formatted --cluster-id $(cat cluster_id) --config config/server.properties

# Start Kafka
systemctl daemon-reload
systemctl enable kafka
systemctl start kafka
```

### templates/kafka.service.tftpl
```
[Unit]
Description=Apache Kafka Server
After=network.target

[Service]
Type=simple
User=root
Group=root
WorkingDirectory=/opt/kafka
Environment="JAVA_HOME=/opt/java"
ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
ExecStop=/opt/kafka/bin/kafka-server-stop.sh
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

## Terraform Commands
To deploy this project, navigate to the `tf-kafka-user-data/` directory and run the following commands in sequence. Ensure you have AWS credentials configured (e.g., via `aws configure`) and Terraform installed.

1. **Initialize Terraform** (downloads providers and modules):
   ```
   terraform init
   ```

2. **Validate Configuration** (checks for syntax errors):
   ```
   terraform validate
   ```

3. **Format Code** (optional, for consistent styling):
   ```
   terraform fmt
   ```

4. **Plan Deployment** (shows what changes will be made):
   ```
   terraform plan -var-file="your-vars.tfvars" -out=plan.tfplan
   ```
   - Replace `your-vars.tfvars` with a file containing your variable values (e.g., subnet_ids, ami_id, etc.).

5. **Apply Deployment** (creates resources):
   ```
   terraform apply plan.tfplan
   ```

6. **Destroy Resources** (when done, to clean up):
   ```
   terraform destroy -var-file="your-vars.tfvars"
   ```

## Additional Notes
- **Prerequisites**: Ensure the IAM instance profile has permissions for S3 read (for artifacts) and Secrets Manager read (for passwords). VPC, subnets, and security groups must exist.
- **Customization**: Adjust instance_type, EBS volume settings, or Kafka configs as needed. The user_data script assumes an Amazon Linux-like AMI with `aws` CLI and `systemctl`.
- **Security**: Passwords are fetched from AWS Secrets Manager at runtime for security.
- **Testing**: After apply, check ASG instances in AWS Console and verify Kafka cluster health using Kafka tools.